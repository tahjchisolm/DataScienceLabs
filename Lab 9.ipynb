{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "cell_id": "5ba6e568-cfda-4b16-8d01-3556c9ede91b",
    "output_cleared": false
   },
   "source": [
    "# Data Munging Part II - Filtering and Joining Datasets\n",
    "This lab was adapted from # Glassdoor Jobs Data-Analysis \n",
    "https://github.com/Atharva-Phatak/Glassdoor-Jobs_Data-Analysis\n",
    "\n",
    "In Data Munging Part I we learned how to explore our data and clean it up so that missing values are removed.\n",
    "\n",
    "In this Data Munging Part II lab, we are going to learn how to:\n",
    "1. Filter our Data\n",
    "2. Sort Data \n",
    "3. Merge/Concatenate Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the point of data munging is to `wrangle` multiple data sources so that you can begin to perform data analysis on the data that you were given or scraped from the web. \n",
    "\n",
    "In most cases you are given a dataset and you must supplement your dataset with sources from web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will perform analysis of Glassdoor data\n",
    "\n",
    "## About Glassdoor\n",
    "\n",
    "![glass](https://upload.wikimedia.org/wikipedia/commons/e/e1/Glassdoor_logo.svg)\n",
    "\n",
    "\"Glassdoor is one of the world’s largest job and recruiting sites.\n",
    "\n",
    "Built on the foundation of increasing workplace transparency, Glassdoor offers millions of the latest job listings, combined with a growing database of company reviews, CEO approval ratings, salary reports, interview reviews and questions, benefits reviews, office photos and more. Unlike other job sites, all of this information is shared by those who know a company best — the employees. In turn, job seekers on Glassdoor are well-researched and more informed about the jobs and companies they apply to and consider joining. This is why thousands of employers across all industries and sizes turn to Glassdoor to help them recruit and hire quality candidates at scale who stay longer. Glassdoor is available anywhere via its mobile apps.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Write the code to import the pandas, numpy, and matplotlib.pyplot libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Data Cleaning\n",
    "\n",
    "In the next block we are improting the libraries `plotly.express`, `gc`, `re`, and `yellowbrick`. \n",
    "\n",
    "## The gc python library\n",
    "This library is a Garbage Collector¶. This module provides an interface to the optional garbage collector.\n",
    "- It is useful for when you are working with large datasets and you pull out useful informatin from these large datasets and store them in a separate dataframe.\n",
    "- Also useful if you have limited space. Some cloud servers only allow you to use a certain amount of space for free services.  (i.e. Collab, jupyter notebooks, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The re library\n",
    "This is the regular expression library. You should have already been introduced to this in a previous lab. \n",
    "Go here: https://docs.python.org/3/library/re.html for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yellowbrick library\n",
    "visual analysis and diagnostic tools\n",
    "you may need to install it to get it to work\n",
    "\n",
    "`pip install yellowbrick`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.8/site-packages (4.11.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from plotly) (1.15.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.8/site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.3.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.1.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.0.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2020.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.4.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from nltk) (1.15.0)\n",
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 4.1 MB/s eta 0:00:01    |█                               | 819 kB 4.1 MB/s eta 0:00:06\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.5.2)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-4.0.1.tar.gz (117 kB)\n",
      "\u001b[K     |████████████████████████████████| 117 kB 60.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.8/site-packages (from gensim) (1.19.2)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-4.0.1-py3-none-any.whl size=108249 sha256=7ac23dc5a83be0f3c1c2243830f0401ac0b0c730c859133a587c1d4f15dfa426\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8c/f9/f4/4ddd9ddee3488f48be20e9bf3108961f03ae23da29b7ed26d1\n",
      "Successfully built smart-open\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.8.3 smart-open-4.0.1\n",
      "Collecting yellowbrick\n",
      "  Downloading yellowbrick-1.2-py3-none-any.whl (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from yellowbrick) (3.3.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from yellowbrick) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from yellowbrick) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /opt/conda/lib/python3.8/site-packages (from yellowbrick) (0.23.2)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /opt/conda/lib/python3.8/site-packages (from yellowbrick) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (8.0.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2020.6.20)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20->yellowbrick) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.20->yellowbrick) (2.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10.0->yellowbrick) (1.15.0)\n",
      "Installing collected packages: yellowbrick\n",
      "Successfully installed yellowbrick-1.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install plotly\n",
    "!pip install seaborn\n",
    "!pip install nltk\n",
    "!pip install gensim\n",
    "!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "cell_id": "517b3ecd-c2a1-47ad-b6a8-aa965e168770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datascience in /opt/conda/lib/python3.8/site-packages (0.17.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datascience) (1.1.3)\n",
      "Requirement already satisfied: coveralls in /opt/conda/lib/python3.8/site-packages (from datascience) (2.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from datascience) (1.19.2)\n",
      "Requirement already satisfied: folium>=0.9.1 in /opt/conda/lib/python3.8/site-packages (from datascience) (0.11.0)\n",
      "Requirement already satisfied: nbsphinx in /opt/conda/lib/python3.8/site-packages (from datascience) (0.7.1)\n",
      "Requirement already satisfied: coverage in /opt/conda/lib/python3.8/site-packages (from datascience) (5.3)\n",
      "Requirement already satisfied: bokeh in /opt/conda/lib/python3.8/site-packages (from datascience) (2.2.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from datascience) (49.6.0.post20201009)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from datascience) (3.3.2)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.8/site-packages (from datascience) (7.18.1)\n",
      "Requirement already satisfied: branca in /opt/conda/lib/python3.8/site-packages (from datascience) (0.4.1)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.8/site-packages (from datascience) (4.11.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from datascience) (1.5.2)\n",
      "Requirement already satisfied: sphinx in /opt/conda/lib/python3.8/site-packages (from datascience) (3.2.1)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.8/site-packages (from datascience) (6.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas->datascience) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datascience) (2.8.1)\n",
      "Requirement already satisfied: docopt>=0.6.1 in /opt/conda/lib/python3.8/site-packages (from coveralls->datascience) (0.6.2)\n",
      "Requirement already satisfied: requests>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from coveralls->datascience) (2.24.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/conda/lib/python3.8/site-packages (from folium>=0.9.1->datascience) (2.11.2)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.8/site-packages (from nbsphinx->datascience) (4.4.0)\n",
      "Requirement already satisfied: nbconvert!=5.4 in /opt/conda/lib/python3.8/site-packages (from nbsphinx->datascience) (5.6.1)\n",
      "Requirement already satisfied: traitlets in /opt/conda/lib/python3.8/site-packages (from nbsphinx->datascience) (4.3.3)\n",
      "Requirement already satisfied: docutils in /opt/conda/lib/python3.8/site-packages (from nbsphinx->datascience) (0.16)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.8/site-packages (from bokeh->datascience) (3.7.4.3)\n",
      "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.8/site-packages (from bokeh->datascience) (6.0.4)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.8/site-packages (from bokeh->datascience) (5.3.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.8/site-packages (from bokeh->datascience) (8.0.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.8/site-packages (from bokeh->datascience) (20.4)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->datascience) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->datascience) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->datascience) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->datascience) (2.4.7)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (3.0.8)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (0.17.2)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (2.7.1)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython->datascience) (4.4.2)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /opt/conda/lib/python3.8/site-packages (from plotly->datascience) (1.3.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from plotly->datascience) (1.15.0)\n",
      "Requirement already satisfied: babel>=1.3 in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (2.8.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (0.7.12)\n",
      "Requirement already satisfied: imagesize in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.2.0)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.1.4)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /opt/conda/lib/python3.8/site-packages (from sphinx->datascience) (1.0.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from pytest->datascience) (20.2.0)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.8/site-packages (from pytest->datascience) (0.10.1)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.8/site-packages (from pytest->datascience) (0.13.1)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.8/site-packages (from pytest->datascience) (1.1.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.8/site-packages (from pytest->datascience) (1.9.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests>=1.0.0->coveralls->datascience) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=1.0.0->coveralls->datascience) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=1.0.0->coveralls->datascience) (1.25.10)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2>=2.9->folium>=0.9.1->datascience) (1.1.1)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.8/site-packages (from nbformat->nbsphinx->datascience) (4.6.3)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from nbformat->nbsphinx->datascience) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat->nbsphinx->datascience) (3.2.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (3.2.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (1.4.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.4.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.3)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert!=5.4->nbsphinx->datascience) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->datascience) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.10->ipython->datascience) (0.7.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython->datascience) (0.6.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->nbsphinx->datascience) (0.17.3)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert!=5.4->nbsphinx->datascience) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import nltk \n",
    "import plotly.express as px\n",
    "import gc\n",
    "import string\n",
    "import re\n",
    "import yellowbrick\n",
    "\n",
    "#!pip install pandas plotnine\n",
    "!pip install datascience\n",
    "\n",
    "#from plotnine import *\n",
    "from datascience import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.options.display.max_columns = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Write the code to use pandas to load the csv files Data_Job_NY.csv, Data_Job_SF.csv, Data_Job_TX.csv, and Data_Job_WA.csv into dataframes.\n",
    "Name the dataframes `ny_df`, `sf_df`, `tx_df`, and `wa_df`\n",
    "\n",
    "Remember that your csv files should be located in the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_df = pd.read_csv(\"Data_Job_NY.csv\")\n",
    "sf_df = pd.read_csv(\"Data_Job_SF.csv\")\n",
    "tx_df = pd.read_csv(\"Data_Job_TX.csv\")\n",
    "wa_df = pd.read_csv(\"Data_Job_WA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Write the code to print out the count, mean, std, min, and max of all of the datasets loaded. \n",
    "Note: You'll have to run the code in a separate cell for each of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33789.711111</td>\n",
       "      <td>49847.461111</td>\n",
       "      <td>3.922727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40201.559469</td>\n",
       "      <td>59552.391775</td>\n",
       "      <td>0.651320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64829.000000</td>\n",
       "      <td>87057.000000</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>125410.000000</td>\n",
       "      <td>212901.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Min_Salary     Max_Salary      Rating\n",
       "count  900.000000     900.000000     660.000000\n",
       "mean   33789.711111   49847.461111   3.922727  \n",
       "std    40201.559469   59552.391775   0.651320  \n",
       "min   -1.000000      -1.000000       2.500000  \n",
       "25%   -1.000000      -1.000000       3.500000  \n",
       "50%    20000.000000   35000.000000   4.000000  \n",
       "75%    64829.000000   87057.000000   4.300000  \n",
       "max    125410.000000  212901.000000  5.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.00000</td>\n",
       "      <td>808.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75989.293588</td>\n",
       "      <td>105111.84027</td>\n",
       "      <td>3.915223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>56101.457881</td>\n",
       "      <td>75131.99965</td>\n",
       "      <td>0.666049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>88309.000000</td>\n",
       "      <td>125886.00000</td>\n",
       "      <td>3.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>117464.000000</td>\n",
       "      <td>160387.00000</td>\n",
       "      <td>4.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>205735.000000</td>\n",
       "      <td>315439.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Min_Salary    Max_Salary      Rating\n",
       "count  889.000000     889.00000     808.000000\n",
       "mean   75989.293588   105111.84027  3.915223  \n",
       "std    56101.457881   75131.99965   0.666049  \n",
       "min   -1.000000      -1.00000       1.300000  \n",
       "25%   -1.000000      -1.00000       3.600000  \n",
       "50%    88309.000000   125886.00000  3.900000  \n",
       "75%    117464.000000  160387.00000  4.400000  \n",
       "max    205735.000000  315439.00000  5.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>643.000000</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49856.833593</td>\n",
       "      <td>75973.337481</td>\n",
       "      <td>3.742589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>37174.830891</td>\n",
       "      <td>55070.548762</td>\n",
       "      <td>0.593329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51465.000000</td>\n",
       "      <td>86476.000000</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77272.000000</td>\n",
       "      <td>114060.000000</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>195818.000000</td>\n",
       "      <td>383416.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Min_Salary     Max_Salary      Rating\n",
       "count  643.000000     643.000000     587.000000\n",
       "mean   49856.833593   75973.337481   3.742589  \n",
       "std    37174.830891   55070.548762   0.593329  \n",
       "min   -1.000000      -1.000000       1.000000  \n",
       "25%   -1.000000      -1.000000       3.400000  \n",
       "50%    51465.000000   86476.000000   3.800000  \n",
       "75%    77272.000000   114060.000000  4.100000  \n",
       "max    195818.000000  383416.000000  5.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>892.000000</td>\n",
       "      <td>794.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60523.627803</td>\n",
       "      <td>92022.095291</td>\n",
       "      <td>3.758564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41024.359069</td>\n",
       "      <td>59570.260961</td>\n",
       "      <td>0.567140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27842.000000</td>\n",
       "      <td>56870.000000</td>\n",
       "      <td>3.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67662.000000</td>\n",
       "      <td>106081.500000</td>\n",
       "      <td>3.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>90930.250000</td>\n",
       "      <td>128731.250000</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>179685.000000</td>\n",
       "      <td>294949.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Min_Salary     Max_Salary      Rating\n",
       "count  892.000000     892.000000     794.000000\n",
       "mean   60523.627803   92022.095291   3.758564  \n",
       "std    41024.359069   59570.260961   0.567140  \n",
       "min   -1.000000      -1.000000       1.000000  \n",
       "25%    27842.000000   56870.000000   3.400000  \n",
       "50%    67662.000000   106081.500000  3.700000  \n",
       "75%    90930.250000   128731.250000  4.100000  \n",
       "max    179685.000000  294949.000000  5.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Write the code to print the first 2 rows of the NY dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Job_Desc</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>Valid_until</th>\n",
       "      <th>Job_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chief Marketing Officer (CMO)</td>\n",
       "      <td>National Debt Relief</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Who We're Looking For:\\n\\nThe Chief Marketing Officer (CMO) is an exempt, executive position, responsible for all marketing operations of the company including lead acquisition, sales enablement, communications, retention, and brand development. This executive leads a team of enthusiastic, analytical, and passionate marketing professionals to develop, execute, and optimize the marketing strategy. We are looking for someone with a history of brand development and proven ability to accelerate company growth leveraging the latest marketing strategies and technologies. This role goes beyond traditional marketing tactics to generate awareness, educate the consumer on the viability of our service, and in turn drive the consumer to take action and engage the brand.\\n\\nPrincipal Duties and Responsibilities:\\n\\nLead the full marketing strategy and have accountability over development, execution, and optimization across all channels including paid and organic search, display, email, social, TV, radio, direct mail, and affiliate marketing.\\nCommunicate with the leadership team and key stakeholders to execute lead generation, sales enablement, and retention-based marketing campaigns that align with and deliver against business goals.\\nDevelop and execute social media, content, and communication strategies to further our public relations and community engagement.\\nIdentify, forge, and grow strategic marketing partnerships.\\nBuild a highly efficient and capable team of marketing professionals.\\nDefine the competitive marketplace and evolve our brand awareness through strategy development and brand building tactics.\\nLead research and development into new marketing tactics and strategies while improving current systems.\\nEstablish key metrics and manage goals while leading the improvement of our pipeline for sales.\\nEstablish framework for all marketing activity, tracking results and reporting progress with management.\\nDevelop segmentation, competitive analysis, market intelligence, salesforce effectiveness, strategic planning and revenue retention and growth.\\n\\nQualifications:\\n\\nA completed BS degree in Business, Marketing, Advertising or other related discipline.\\nMinimum experience required 10+ years of professional experience in a leadership marketing role.\\nExperience building and executing brand awareness and public relations campaigns.\\nExperience in a fast-growing company with a track record of delivering big results.\\nHighly proficient and effective communication skills\\nAbility to utilize data analytics to deliver insight and identify opportunities for growth.\\nA strong record of developing successful, innovative and cost-effective marketing campaigns.\\nPunctual and ready to report to work on a consistent basis.\\nTravel up to 25 percent of the time.\\nExcel in a fast-paced environment.\\n\\nWhat We Offer:\\n\\nA team-first, work hard play hard culture, full of rewards and recognition for our employees. We are dedicated to our employees' success and growth.\\n\\nOur extensive benefits package includes:\\n\\n\\nGenerous Medical, Dental, and Vision Benefits\\n401(k) with Company Match\\nPaid Holidays, Volunteer Time Off, Sick Days, and Vacation\\n10 weeks Paid Parental Leave\\nPre-tax Transit Benefits\\nDiscounted Gym Membership\\nCiti Bike Annual Membership Discounts\\nNo-Cost Life Insurance Benefits\\nVoluntary Benefits Options\\nASPCA Pet Health Insurance Discount\\n\\nAbout National Debt Relief:\\n\\nNational Debt Relief is one of the country's largest and most reputable debt settlement companies. We are made up of energetic, smart, and compassionate individuals who are passionate about helping thousands of Americans with debt relief. Most importantly, we're all about helping our customers through a tough financial time in their lives with education and individual customer service.\\n\\nWe are dedicated to helping individuals and families rid their lives of burdensome debt. We specialize in debt settlement and have negotiated settlements for thousands of creditor and collections accounts. We provide our clients with both our expertise and our proven results. This means helping consumers in their time of hardship to get out of debt with the least possible cost. It can also mean conducting financial consultations, educating the consumer, and recommending the appropriate solution. Our core services offer debt settlement as an alternative to bankruptcy, credit counseling, and debt consolidation. We become our clients' number one advocate to help them reestablish financial stability as quickly as possible.\\n\\nNational Debt Relief is a certified Great Place to Work®!\\n\\nNational Debt Relief is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other status protected by law\\n\\n#ZR</td>\n",
       "      <td>Finance</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Registered Nurse</td>\n",
       "      <td>Queens Boulevard Endoscopy Center</td>\n",
       "      <td>NY</td>\n",
       "      <td>Rego Park</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Queens Boulevard Endoscopy Center, an endoscopy ASC located in Rego Park, has an exciting opportunity for Full-Time Registered Nurse! Successful candidates will provide quality nursing care in all areas of the Center including pre-assessment, pre-op and pacu  Qualified candidates must possess the following:\\n\\nCurrent NY state RN license\\nBLS Certification, ACLS preferred\\nMust be a team-player with excellent multi-tasking and interpersonal skills\\nCompassion for patient needs and a high degree of professionalism\\nChinese Speaking and Spanish Preferred\\n\\nQueens Boulevard Endoscopy Center offers a pleasant professional work environment and no evening or holiday work hours. Drug-free work environment and EOE.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Job_title  ...   Job_Type\n",
       "0  Chief Marketing Officer (CMO)  ...  FULL_TIME\n",
       "1  Registered Nurse               ...  FULL_TIME\n",
       "\n",
       "[2 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Write the code to print the name of the columns for only one of the dataframes\n",
    "\n",
    "Note: the data was scrapted from glassdoor and will have the same column information for each dataframe loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job_title', 'Company', 'State', 'City', 'Min_Salary', 'Max_Salary',\n",
       "       'Job_Desc', 'Industry', 'Rating', 'Date_Posted', 'Valid_until',\n",
       "       'Job_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c26eda34-205d-4a63-9182-4ac694ed19b7",
    "tags": []
   },
   "source": [
    "## ***Information About the columns present in the Data***\n",
    "\n",
    "1. The 12 columns in the datasets:\n",
    "    * ***Job_title*** : The title of job which you are applying to\n",
    "    * ***Company*** : Company name\n",
    "    * ***State/City*** : State/City in which the companies job posting is listed.\n",
    "    * ***Min_Salary*** : Minimum yearly salary in USD.\n",
    "    * ***Max_Salary*** : Maximum yearly salary in USD.\n",
    "    * ***Job_Desc*** : The job description which included skills,requirements,etc\n",
    "    * ***Industry*** : The industry in which the company works.\n",
    "    * ***Date_posted*** : The date  on which the job was posted on glassdoor\n",
    "    * ***Valid_until*** : The last date of applying to the job.\n",
    "    * ***Job_Type*** : Type of job full-time , part-time,etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting column names\n",
    "\n",
    "You can sort the names of the columns alphabettically using the below `sorted` function\n",
    "`sorted(df)` where df is the name of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Write the code to sort the column names alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'Company',\n",
       " 'Date_Posted',\n",
       " 'Industry',\n",
       " 'Job_Desc',\n",
       " 'Job_Type',\n",
       " 'Job_title',\n",
       " 'Max_Salary',\n",
       " 'Min_Salary',\n",
       " 'Rating',\n",
       " 'State',\n",
       " 'Valid_until']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ny_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining OR Concatenating Dataframes\n",
    "To join dataframes together use the panda function `concat`.\n",
    "`pd.concat(df1, df2, df3, ..., dfn)` where pd is the panda library name and df1 is dataframe1, df2 is dataframe2, and df3 is dataframe3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "a5ab06c9-3fb5-4b41-a3a2-69f22b7bca6e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_df = pd.concat([ny_df , sf_df , tx_df, wa_df] , axis = 0 , ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage Collection\n",
    "In some cases you should perform garbage collection to clear up your workspace\n",
    "This is especially true when working on cloud-based systems like Collab or Jupyter notebooks\n",
    "\n",
    "Use the `gc.collect()` function to clean up any dataframes that you don't need anymore\n",
    "To do this you'll need to delete them first then call `gc.collect()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "cell_id": "4a80b5b4-163d-4e4b-a243-2bf4ee8b890b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del ny_df , sf_df , tx_df ,wa_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. Write the output from the collect function below\n",
    "\n",
    "198\n",
    "\n",
    "## Q8. What do you think it means?\n",
    "\n",
    "That could be the number of value or rows that were deleted and collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3c7fd77a-44b2-4e40-9263-99e82b635903",
    "tags": []
   },
   "source": [
    "# Beginning Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. How many rows and columns does your all_df have? Write the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "e59071bd-25f5-40ed-9ee5-adb9e7139db3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3324, 12)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "e9742998-e646-41fb-a082-a3f2c30369cc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3324 entries, 0 to 3323\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Job_title    3324 non-null   object \n",
      " 1   Company      3324 non-null   object \n",
      " 2   State        3322 non-null   object \n",
      " 3   City         3318 non-null   object \n",
      " 4   Min_Salary   3324 non-null   int64  \n",
      " 5   Max_Salary   3324 non-null   int64  \n",
      " 6   Job_Desc     3324 non-null   object \n",
      " 7   Industry     2700 non-null   object \n",
      " 8   Rating       2849 non-null   float64\n",
      " 9   Date_Posted  3324 non-null   object \n",
      " 10  Valid_until  3324 non-null   object \n",
      " 11  Job_Type     3324 non-null   object \n",
      "dtypes: float64(1), int64(2), object(9)\n",
      "memory usage: 311.8+ KB\n"
     ]
    }
   ],
   "source": [
    "all_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data to Sort and Filter it\n",
    "\n",
    "Sometimes the data you are given or that you have scraped will need to be converted to another format. \n",
    "\n",
    "In all_df, we'll mainly we working with min_salary and max_salary\n",
    "\n",
    "To work with these values we'll need to convert them to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "3d2158e1-6eff-4fd3-bef5-53320e36eb26",
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_df['Min_Salary'] = all_df['Min_Salary'].apply(lambda x : int(x))\n",
    "all_df['Max_Salary'] = all_df['Max_Salary'].apply(lambda x : int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Dates in Datasets\n",
    "Many datasets have dates within them\n",
    "To work with dates, and to sort and filter them properly you may need to work with only the month\n",
    "or only the year or only the day.\n",
    "\n",
    "Use the `calendar` library as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "6ee4f7e1-c616-4880-82a7-419ab8c46232",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "all_df['Month'] = all_df['Date_Posted'].apply(lambda x : calendar.month_abbr[int(str(x).split('-')[1])]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10 Write the code to extract the date and day from Valid Until column. \n",
    "data is the format y-m-d\n",
    "Name it `all_df['Valid_Month']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['Valid_Month'] = all_df['Valid_until'].apply(lambda x : calendar.month_abbr[int(str(x).split('-')[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Dates to Day\n",
    "Sometimes you will need to convert a date into a given day\n",
    "To do this, you can use the function created below called \n",
    "`Convert_to_Day`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "d0556fcb-efdd-43d5-b752-515983645740",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Convert_to_Day(x):\n",
    "    sl = x.split('-')  \n",
    "    return calendar.day_abbr[int(calendar.weekday(int(sl[0]) , int(sl[1]) , int(sl[2])))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11. Use the Convert to Day function to convert the Date_Posted and Valid_Until values to days\n",
    "Print out row 105 in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tue', 'Sun')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Convert_to_Day(all_df['Date_Posted'][105]), Convert_to_Day(all_df['Valid_until'][105])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisiting Working with Missing Data\n",
    "In Data Munging Part I, we removed missing data\n",
    "\n",
    "Sometimes you'll want to save that data for later so you can do some analysis on the erroneously provided or missing data\n",
    "This is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "894e3b68-39c8-4ae7-905c-fdd55849c24e",
    "output_cleared": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    9,   12,   16,   17,   19,   20,   21,\n",
       "            ...\n",
       "            3289, 3292, 3293, 3295, 3296, 3300, 3301, 3302, 3303, 3304],\n",
       "           dtype='int64', length=1092)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_missing = all_df[(all_df['Min_Salary'] == -1)].index\n",
    "test_df = all_df.iloc[index_missing, :].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11. Now that you have this missing data, you can now drop it from the dataframe. Write the code to do this below.\n",
    "**Hint: You should use the function `drop` that follows this format\n",
    "`df.drop(missing_data_index, axis=0, inplace=True)` where `df` is the dataframe\n",
    "and `missing_data_index` is a list of rows to drop from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.drop(index_missing, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Duplicates\n",
    "Sometimes in your dataset because it is scraped from the web, there may be duplicates\n",
    "You'll need to check for these duplicates because it will impace your data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "05f30f12-33e9-476d-bcc0-67ebf2620207",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = [col for col in all_df.columns if col not in ['Day' , 'Month']]\n",
    " \n",
    "train_series = all_df.duplicated(cols , keep = 'first')\n",
    "data_df      = all_df[~train_series].reset_index(drop = True)\n",
    "test_series  = test_df.duplicated(cols , keep = 'first')\n",
    "test_df      = test_df[~test_series].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking for Unique Values in your Dataframe\n",
    "Sometiems you'll need to look for unique values in your dataframe \n",
    "Use the `unique` function to do this\n",
    "Follows this format `df['COL_NAME'].unique()` where df is the dataframe and COL_NAME is the column name in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "c82dc428-161a-48f0-9d1c-e9f957598ad7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NY' 'NJ' 'CA' 'KY' 'TX' 'TN' 'VA' 'MD' 'DC' 'NC']\n"
     ]
    }
   ],
   "source": [
    "print(all_df['State'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12. Write the code to count the number of unique States from the previous operation. Name the variable num_states and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_states = len(all_df['State'].unique())\n",
    "num_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "c7241844-5914-4c55-b335-12ed126b16ad",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State of NY\n",
      "New York          240\n",
      "Williston Park    30 \n",
      "Rego Park         30 \n",
      "Maspeth           30 \n",
      "Staten Island     30 \n",
      "Name: City, dtype: int64\n",
      "State of NJ\n",
      "Paramus        30\n",
      "Jersey City    30\n",
      "Name: City, dtype: int64\n",
      "State of CA\n",
      "San Francisco          302\n",
      "South San Francisco    122\n",
      "Menlo Park             29 \n",
      "San Mateo              27 \n",
      "Redwood City           20 \n",
      "Name: City, dtype: int64\n",
      "State of KY\n",
      "Florence    1\n",
      "Name: City, dtype: int64\n",
      "State of TX\n",
      "Austin         132\n",
      "Dallas         79 \n",
      "Houston        67 \n",
      "San Antonio    41 \n",
      "Irving         40 \n",
      "Name: City, dtype: int64\n",
      "State of TN\n",
      "Chennai    1\n",
      "Name: City, dtype: int64\n",
      "State of VA\n",
      "Arlington      77\n",
      "McLean         50\n",
      "Reston         35\n",
      "Springfield    34\n",
      "Alexandria     29\n",
      "Name: City, dtype: int64\n",
      "State of MD\n",
      "Gaithersburg     41\n",
      "Rockville        36\n",
      "Silver Spring    25\n",
      "College Park     23\n",
      "Bethesda         20\n",
      "Name: City, dtype: int64\n",
      "State of DC\n",
      "Washington    155\n",
      "Name: City, dtype: int64\n",
      "State of NC\n",
      "Raleigh    1\n",
      "Name: City, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for state in all_df['State'].unique():\n",
    "    print(f\"State of {state}\")\n",
    "    print(all_df[all_df['State'] == state]['City'].value_counts()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q13. What city has the most job openings? Write your answer below\n",
    "\n",
    "San Fransico has the most with 302."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q14. What city has the least job openings? What states do they occur in?\n",
    "\n",
    "Florence of KY, Chennai of TN and Raleigh of NC all only have one opening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying and Removing Outliers\n",
    "In some cases you'll have outliers in your data. \n",
    "An `outlier` is an observation that lies an abnormal distance from other values in a random sample from a population. \n",
    "Sometimes negative numbers, zero, or really large numbers can be outliers in your sample population\n",
    "\n",
    "See your textbook Sampling from a Population https://www.inferentialthinking.com/chapters/10/2/Sampling_from_a_Population.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_outlier = all_df[(all_df['State'] =='NC') | (all_df['State'] =='TN') | (all_df['State'] =='KY')].index\n",
    "all_df.drop(index_outlier , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "62149f95-3267-4876-b625-3f56011562d0",
    "tags": []
   },
   "source": [
    "# Visualizing the Data with pie charts\n",
    "The below code shows how to make a pie chart for the CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "10f7b273-f2e8-4efc-b77a-670bc1d61505",
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_state = all_df[(all_df['State'] =='CA')].index\n",
    "for i,state in enumerate(max_state,1):\n",
    "    cities = all_df[all_df['State'] == state]['City'].value_counts()[:5].index.to_list()\n",
    "    counts = all_df[all_df[\"State\"] == state]['City'].value_counts()[:5].to_list()\n",
    "\n",
    "my_colors  = ['lightgray','lightblue','crimson', 'beige', 'yellow']\n",
    "my_explode = (0, 0.1, 0)\n",
    "\n",
    "plt.pie(counts,labels=cities,autopct='%1.1f%%',startangle=15, shadow = True, colors=my_colors, normalize=False)\n",
    "plt.title('California GlassDoor Cities')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q15. Write the code to create a pie chart for TX. \n",
    "\n",
    "Add a title to your pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "4bc3c3b4-0926-4085-a064-5495faabaafc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_state = ['TX' ]\n",
    "for i,state in enumerate(max_state,1):\n",
    "    cities = all_df[all_df['State'] == state]['City'].value_counts()[:5].index.to_list()\n",
    "    counts = all_df[all_df[\"State\"] == state]['City'].value_counts()[:5].to_list()\n",
    "\n",
    "my_colors  = ['lightblue','lightsteelblue','silver', 'lightgrey', 'crimson']\n",
    "my_explode = (0, 0.1, 0)\n",
    "\n",
    "plt.pie(counts,labels=cities,autopct='%1.1f%%',startangle=15, shadow = True, colors=my_colors)\n",
    "plt.title('Texas GlassDoor Cities')\n",
    "plt.axis('equal')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Groupby functionality\n",
    "A groupby operation involves some combination of splitting the object, \n",
    "applying a function, and combining the results. \n",
    "\n",
    "This can be used to group large amounts of data and compute operations on these groups.\n",
    "\n",
    "This is shown in the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "c039b142-8093-4ee0-920e-1ac38019eae8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State\n",
       "CA    29611\n",
       "DC    21096\n",
       "MD    20268\n",
       "NJ    38471\n",
       "NY    20000\n",
       "TX    19857\n",
       "VA    29516\n",
       "Name: Min_Salary, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = all_df['State'].unique().tolist()\n",
    "\n",
    "min_sal =  all_df.groupby('State')['Min_Salary']\n",
    "max_sal =  all_df.groupby('State')['Max_Salary']\n",
    "\n",
    "min_sal.min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q16. Use the groupby function to find the minimal salary for all companies\n",
    "Print this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company\n",
      "159 Solutions, Inc.          110591\n",
      "1901 Group                   79171 \n",
      "22nd Century Technologies    85715 \n",
      "23andMe                      78913 \n",
      "911 Datamaster Inc           45694 \n",
      "                             ...   \n",
      "price.com                    122998\n",
      "steampunk                    108661\n",
      "sydata                       109626\n",
      "tekwissen                    24457 \n",
      "vidIQ                        137812\n",
      "Name: Min_Salary, Length: 959, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "min_sals =  all_df.groupby('Company')['Min_Salary']\n",
    "print(min_sals.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f438a547-c093-4935-a5ef-edd1d4fe86e5",
    "tags": []
   },
   "source": [
    "## Extracting Features out of Job Description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "c762fb3d-281a-4141-823c-b11bac56f931",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = all_df.Job_Desc.str.replace('\\n\\n', '\\n')\n",
    "x = x.str.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d9074848-e4f7-42c6-aaf4-595b712909ea",
    "tags": []
   },
   "source": [
    "## Q17. What are some observations that you noticed about the job description column. What's the format or structure of the job description\n",
    "\n",
    "The responsibilities are split by '\\n'.\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Cleaning up HTML Artifiacts \n",
    "Sometimes you will need to clean up the data\n",
    "Use the regular expression library to do that\n",
    "Use the `replace` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "_kg_hide-input": true,
    "cell_id": "e465590a-695d-4905-bd2d-b96ad02278cf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emergency VeterinarianThe family joining VEG rapidly growing group emergency practices multiple locations single mission Helping People Their Pets When They Need Most We changing face emergency veterinary medicine “client first” mentality We’re group passionate thought leaders believe power open mind servant leadership If you’re ideal candidate you’ll Have earned DVM equivalent degree Be fulfilled helping Thrive teamoriented environments think hospital retreats team dinners happy hours Have ‘glass half full’ attitude sense humor Live breathe emergency medicine Be passionate emergency surgery soft tissue kind Benefits Why choose Because emergency best We offer Industryleading compensation signing bonus monthly bonuses Health Insurance 401K w company match Unlimited CE Flexible work schedules true worklife balance 3 shifts week fulltime Growth potential Fresh groceries sent weekly monthly quarterly contests quarterly hospital outings annual companywide retreat'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['Job_Desc'] = all_df['Job_Desc'].replace('\\n\\n' , \" \" , regex = True)\n",
    "all_df['Job_Desc'] = all_df['Job_Desc'].replace('\\n' , \" \" , regex = True)\n",
    "\n",
    "test_df['Job_Desc'] = test_df['Job_Desc'].replace('\\n\\n' , \" \" , regex = True)\n",
    "test_df['Job_Desc'] = test_df['Job_Desc'].replace('\\n' , \" \" , regex = True)\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "def Remove_puncutations_stopwords(s):\n",
    "\n",
    "    s = ''.join([i for i in s if i not in string.punctuation])\n",
    "    s = remove_stopwords(s)\n",
    "    return s\n",
    "\n",
    "data_df['Job_Desc'] = data_df['Job_Desc'].apply(lambda x : Remove_puncutations_stopwords(x))\n",
    "\n",
    "data_df['Job_Desc'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Data\n",
    "After you worked with some data sometimes you'll need to save it to work with later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(\"all_data.csv\" , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Job_Desc</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>Valid_until</th>\n",
       "      <th>Job_Type</th>\n",
       "      <th>Month</th>\n",
       "      <th>Valid_Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Salesforce Developer</td>\n",
       "      <td>National Debt Relief</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>44587</td>\n",
       "      <td>82162</td>\n",
       "      <td>Principle Duties &amp; Responsibilities: Analyze complex systems and troubleshoot and isolate system issues; Understand requirements for business users and translate into design specifications, utilizing thorough understanding of the Salesforce platform, Salesforce products and licensing models; Utilize thorough understanding of application development, project lifecycle, and methodologies and ability to work under tight deadlines and handle multiple detail-oriented tasks; Apply knowledge of Salesforce developmentand customizations, with APEX, Visual Force, API, Force.com and Workflows, taking into account com best practices, support mechanisms, procedures, and limitations, as well as NDR's unique needs; Responsible for Salesforce administration, release management and deployment as well as management of Salesforce.com sandboxes, including their integrations; Design and execute Salesforce.com configuration changes, leveraging the Salesforce interface to sync with internal tracking systems; Design, develop, and maintain integration and synchronization programs; Design the data model, user interface, business logic, and security for custom applications; and Design, develop, and customize software solutions for end users by using analysis and mathematical models to effectively predict and measure the results of the design using Chatter, Communities and other Salesforce applications. Requirements: Bachelor of Science degree or foreign equivalent in Information Systems, Computer Science, Computer Engineering, Software Engineering or a related field 3 years of experience with the Salesforce platform, specifically: development with Apex, VisualForce, and Force.com; Design and execute Salesforce.com configuration changes, leveraging the Salesforce interface to sync with internal tracking systems; Salesforce administration, release management, and deployment Salesforce products and licensing models Management of Salesforce.com sandboxes, including their integrations; Chatter, Communities, and other Salesforce apps com best practices, support mechanisms, procedures, and limitations. What We Offer: We believe in a team-first culture, full of rewards and recognition for our employees. We are dedicated to our employees' success and growth within the company, through our employee mentorship and leadership programs. Our extensive benefits package includes:  Medical, Dental, and Vision Benefits 401(k) Match Paid Holidays, Volunteer Time Off, Sick Days, and Vacation 10 Weeks Paid Parental Leave Pre-tax Transit Benefits Discounted Gym Membership No-cost Life Insurance Benefits About National Debt Relief: National Debt Relief is one of the country's largest and most reputable debt settlement companies. We are made up of energetic, smart, and compassionate individuals who are passionate about helping thousands of Americans with debt relief. Most importantly, we're all about helping our customers through a tough financial time in their lives with education and individual customer service. We are dedicated to helping individuals and families rid their lives of burdensome debt. We specialize in debt settlement and have negotiated settlements for thousands of creditor and collections accounts. We provide our clients with both our expertise and our proven results. This means helping consumers in their time of hardship to get out of debt with the least possible cost. It can also mean conducting financial consultations, educating the consumer, and recommending the appropriate solution. Our core services offer debt settlement as an alternative to bankruptcy, credit counseling, and debt consolidation. We become our clients' number one advocate to help them reestablish financial stability as quickly as possible. #ZR</td>\n",
       "      <td>Finance</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEPUTY EXECUTIVE DIRECTOR, PROGRAM AND LEGAL ADVOCACY</td>\n",
       "      <td>National Advocates for Pregnant Women</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>125410</td>\n",
       "      <td>212901</td>\n",
       "      <td>For FULL Job Announcement, visit our website: www.AdvocatesForPregnantWomen.org Reporting to and working collaboratively with the Executive Director (ED), the Deputy Executive Director, Program &amp; Legal Advocacy (DED) is a member of the Senior Management Team (SMT) providing leadership for and supervision of NAPW’s legal team and taking responsibility for the day-to-day program operations of the organization. The DED as an experienced senior level attorney with executive management experience and serves as a strategic thought partner and advisor to the Executive Director and the SMT. In absence of the Executive Director, the DED (in consultation with the COO), is designated as the highest authority to respond to internal and external inquiries, make programmatic/advocacy decisions, and represent NAPW in any and all responsibilities assigned to the ED. Responsibilities include (but are not limited to): Partnering with the ED to create and implement NAPW’s mission-work and strategic planning;Working collaboratively with the SMT (collectively responsible for the critical business functions of Program, Finance/Operations, Human Resources, Communications, and Development/Grant Administration), to develop and implement administrative policies and procedures for guiding operations, strengthening internal systems, ensuring high levels of staff engagement, managing performance, encouraging continuous learning, and promoting administrative and programmatic alignment;Helping to create NAPW’s reproductive justice public policy/public advocacy initiatives and determining when NAPW supports and/or joins related allied efforts by other organizations;Directly supervising the day-to-day work of the Senior Staff Attorneys, Staff Attorneys, post-graduate Fellows, legal &amp; programmatic interns, legal contractors, loaned associates, and Research and Program Associates. Supervision includes coaching and training, performance review, assigning and reviewing work, mentoring, analysis and editing of written work and providing the ED with sufficient time to review; Minimum qualifications include: JD degree from an accredited law school is required; Membership in at least 1 (one) state AND federal bar is required;Master’s Degree in Non-profit Management, Public Policy, Social Work, or a related field is highly-desirable;8-10 years: of senior-level management experience in a non-profit legal advocacy/public interest/social justice environment, with demonstrable success in change implementation; complex litigation and advocacy experience as an attorney providing direct client representation, with a particular emphasis in public interest law and reproductive justice and drug policy litigation in state and federal courts; experience in the supervision of attorneys and managing programs (and staff);Demonstrated capacity to serve as a member of a Senior Management Team and advisor to the Executive Director on all matters pertaining to NAPW's legal advocacy;Knowledge of and experience in reproductive health, rights, and justice; civil rights with knowledge of drug policy reform, women’s rights, family law, child welfare reform, and human rights is highly-desirable. NOTE: YOUR SUBMISSION WILL BE REJECTED IF YOU HAVE NOT PROVIDED ALL MATERIALS AND INFORMATION AS INSTRUCTED BELOW. REQUIRED SUBMISSIONS (MUST INCLUDE ALL ITEMS LISTED BELOW): 1. Cover Letter which must include all of the following elements: a) Your personal &amp; professional motivation for seeking this position. b) A discussion of what makes you the ideal/best candidate for this position. c) Explain how your skill sets and experience best demonstrate your strategic approach. d) Salary Requirement. e) Indicate where you found this Job Announcement. 2. Resumé. 3. Two (2) Writing Samples solely reflecting applicant’s own work (MUST submit BOTH A and B): a) One Non- legal advocacy writing sample such as an article, commentary or blog. b) One Legal writing sample (i.e., a legal brief, argument or analysis) consisting of NO MORE THAN ten pages of text. 4. Complete contact information for three (3) professional references. INSTRUCTIONS: NO PHONE CALLS OR FAXES PLEASE. All submissions must be sent VIA EMAIL ONLY SUBJECT: ATTN: Human Resources – NAPW Deputy Executive Director, Program &amp; Legal Advocacy (JAN. 2020) Job Type: Full-time Experience: Reproductive Justice/Reproductive Rights legal advocacy: 5 years (Preferred)Non-profit Executive/Senior Management: 8 years (Required)Supervising Attorney: 5 years (Required)Public Interest Law and litigation: 6 years (Required) Education: Doctorate (Required) Work Location: One location Benefits: Health insuranceDental insuranceVision insuranceRetirement planPaid time offParental leaveProfessional development assistanceTuition reimbursement Schedule: Monday to Friday</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emergency Veterinarian - NYC</td>\n",
       "      <td>Veterinary Emergency Group</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>94715</td>\n",
       "      <td>103279</td>\n",
       "      <td>Emergency VeterinarianThe family you will be joining: VEG is a rapidly growing group of emergency practices with multiple locations and a single mission: Helping People and Their Pets When They Need it Most. We are changing the face of emergency veterinary medicine with a “client first” mentality. We’re a group of passionate, thought leaders that believe in the power of an open mind and servant leadership. If you’re the ideal candidate, you’ll: Have earned a DVM or equivalent degree Be fulfilled by helping others Thrive in team-oriented environments (think hospital retreats, team dinners, happy hours and more!) Have a ‘glass half full’ attitude and a sense of humor! Live and breathe emergency medicine Be passionate about emergency surgery (the soft tissue kind!) Benefits Why you should choose us: Because emergency is all we do, so we do it best! We also offer: Industry-leading compensation + signing bonus + monthly bonuses Health Insurance 401K w/ company match Unlimited CE Flexible work schedules for a true work-life balance (3 shifts a week is full-time for us!) Growth potential Fresh groceries sent weekly, monthly and quarterly contests, quarterly hospital outings, annual company-wide retreat, etc!</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABA Therapist</td>\n",
       "      <td>Kids Learning Loft Applied Behavior Analysis Services</td>\n",
       "      <td>NY</td>\n",
       "      <td>Williston Park</td>\n",
       "      <td>20000</td>\n",
       "      <td>35000</td>\n",
       "      <td>Here at Kids Learning Loft Applied Behavior Analysis Services, PLLC, we are the rapidly expanding company in our industry in Williston Park, NY. We are hiring experienced part-time ABA Therapists to help us keep growing. If you're dedicated and ambitious, Kids Learning Loft is an excellent place to grow your career. We offer hands on training and a rigurous supervision program. Don't hesitate to apply.Responsibilities Study patient behavior and apply ABA principles Respond appropriately to different situations common among Autism patients and others with behavioral and developmental challenges Utilize key communication skills to provide effective feedback to patients Effectively communicate positive feedback to patients Be able to recognize and respond to critical improvements in patient behaviors. Become familiar with and use behavioral redirection techniques Know how to respond to negative behaviors appropriately Provide written documentation on each patients. Qualifications Preferred Master's degree in ABA, psychology, education, or related field of study Preferred Registered Behavior Technician certificate from the Behavior Analyst Certification Board. 0-5 years of experience required for entry-level positions Strong communication skills required Ability to work under high-stress situations Exhibits significant reliable habits, including timeliness and organizational skills Proven experience working with pre-school and elementary school-aged children Additional evidence of successful work with patients suffering from Autism and development issues Other experience, certificates, or qualifications as required by state</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>PART_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Construction Project Manager</td>\n",
       "      <td>The LiRo Group</td>\n",
       "      <td>NY</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>54991</td>\n",
       "      <td>143860</td>\n",
       "      <td>Overview Ranked among the nation's top 10 Construction Managers by Engineering News-Record, The LiRo Group provides integrated construction, design, and technology solutions for a broad range of public and private sector clients. Our continued growth has created an immediate need for an experienced Construction Project Manager with strong electrical expertise from both a technical and strategic implementation perspective for a critical hospital electrical upgrade in Brooklyn, NY. Responsibilities Overall construction management team leadership, including effective coordination with hospital patient departments and facility groups Direct communication with client, facility, stakeholders and user groups Oversee and ensure quality and consistency of construction and all aspects of electrical improvements Provide technical evaluations, advice and guidance Coordination with adjacent projects impacted by the proposed work Management of project administrative efforts, including progress reports, submittals, requisitions and change orders Qualifications Bachelor's Degree in Electrical Engineering or related discipline Emergency Power Expereince a must 15+ years' experience in Project Management Strong electrical knowledge, particularly for Type 1 EES Systems Experience in an occupied hospital facility a necessity Strong communication skills at multiple project levels ranging from tradespeople to facility executives Ability to work under tight deadlines and handle multiple tasks Please visit our website for all of our career opportunities at: https://careers-liro.icims.com We offer a competitive salary commensurate with experience, a comprehensive benefits package and a positive work environment. Equal Opportunity Employer PI120130472</td>\n",
       "      <td>Construction, Repair &amp; Maintenance</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>Data Engineer/Architect with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>McLean</td>\n",
       "      <td>74916</td>\n",
       "      <td>128610</td>\n",
       "      <td>Job Number: R0082817 Data Engineer/Architect Key Role: Support the collection, ingestion, storage, processing, and analysis of complex datasets to disseminate mission-critical insights to our clients. Design, architect, implement, monitor, and maintain solutions to enable increasingly complex data analytics. Integrate solutions with broader technology architecture used across the organization while influencing enterprise architecture to meet the needs of the future. Maintain the perspective of the entire client organization, mapping the systems and interfaces used to manage data, setting standards for data management, analyzing the current state and conceiving desired future state, and articulating projects needed to close the gap between the current state and future goals. Basic Qualifications: * 8+ years of experience in data modeling and database design, from conceptualization to database optimization  2+ years of experience with NoSQL databases, including HBase or Cassandra * Experience with Hadoop cluster and all included services, including Hadoop v2, HDFS * Knowledge of Big Data querying tools, including Pig, Hive, or Impala * Knowledge of the system development life cycle; software project management approaches; and requirements, design, and test techniques Knowledge of established and emerging data technologies; conversant in emerging tools like columnar and NoSQL databases, predictive analytics, data visualization, and unstructured data Ability to obtain a security clearance BA or BS degree Additional Qualifications: * Ability to explain advanced concepts to team members, users, and clients Ability to work independently and address ad-hoc challenges Possession of excellent communications skills Possession of excellent problem-solving skills Clearance:  Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>Data Engineer with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>58824</td>\n",
       "      <td>112227</td>\n",
       "      <td>Job Number: R0083152 Data Engineer The Challenge: Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors - from fraud detection, to cancer research, to national intelligence - you know the answers are in the data. We have an opportunity for you to use your analytical skills to improve strategic innovation for the federal government. You'll work closely with your customer to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You'll mentor teammates, develop algorithms, write scripts, build predictive analytics, apply machine learning, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help federal health organizations make informed decisions. You'll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in the federal government. Empower change with us. You Have: -3+ years of experience within data science and engineering -2+ years of experience in working with machine learning models and algorithms, including natural language processing (NLP) -2+ years of experience with object-oriented programming, including Java, Scala, or Python -Experience with Big Data technologies, including HDFS, Hadoop, and Spark -Experience with manipulating data and extract, transform, and load (ETL) in parallel processing and distributed compute environments -Experience with using Cloud services, including AWS and Azure -Ability to learn technical concepts quickly and communicate with multiple functional groups -Secret clearance -BA or BS degree Nice If You Have: -2+ years of experience with designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results -Ability to manage and manipulate large data sets, develop data science approaches, and manage data science tasks -Ability to leverage a wide variety of data science capabilities and languages -Ability to exhibit flexibility, initiative, and innovation when dealing with ambiguous and fast-paced situations -MA or MS degree in Engineering, Statistics, Mathematics, or Data Science Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required Build Your Career: At Booz Allen, we know the power of analytics and we're dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you can expect: * access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk  a chance to change the world with the Data Science Bowl-the world's premier data science for social good competition participation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government You'll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications? Take advantage of our tuition assistance, onsite boot camps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We'll help you develop the career you want, as you chart your own course for success. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change. #LI-AH1, CJ1</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>Data Engineer, Mid with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Herndon</td>\n",
       "      <td>58824</td>\n",
       "      <td>112227</td>\n",
       "      <td>Job Number: R0083073 Data Engineer, Mid Key Role: Leverage expertise in structured and unstructured data to perform data engineering activities on cutting-edge projects in the ind us try working with Big Data tools. Architect data systems and stand up data platforms, build out ETL pipelines, write c us tom code, interface with data stores, perform data ingestion, and build data models. Assess, design, build, and maintain scalable data platforms that us e the latest and best in Big Data tools. Perform analytical exploration and examination of data from multiple sources of data. Work in Scrum-based Agile environment with multi-disciplinary team of analysts, data engineers, data scientists, developers, and data consumers in an agile fast-paced environment that is p us hing the envelope of leading-edge Big Data implementations. Basic Qualifications: -2+ years of experience with developing ETL pipelines and developing data manipulation scripts  2+ years of experience in us ing SQL, working with modern relational databases, including MySQL or PostgreSQL -2+ years of experience with Big Data systems, including Hadoop, HDFS, Hive, or Cloudera -Experience with us ing Lucene based search engines, including elasticsearch or solr Active Secret clearance -BS degree in CS or Information Systems required Additional Qualifications: -Experience with Agile sof tware development -Experience with Big Data ETL tools like StreamSets and NiFi Experience with AWS cloud te chn ologies -Experience in working with enterprise and production systems -Ability to have a positive, can-do attitude to solve the challenges of tomorrow -Ability to learn te chn ical concepts and communicate with multiple functional groups -Possession of excellent oral and written communication skills -Hortonworks, Cloudera, or Big data Certifications Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>Data Modeler, Senior with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>90454</td>\n",
       "      <td>151998</td>\n",
       "      <td>Job Number: R0082912 Data Modeler, Senior The Challenge: Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by the IoT, machine learning, and artificial intelligence advances? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors - from fraud detection, to cancer research, to national intelligence - you know the answers are in the data. We have an opportunity for you to use your leadership and analytical skills to improve a department of defense client. You'll work closely with your customer to understand their questions and needs, and then dig into their data-rich environment to find the pieces of their information puzzle. You'll mentor teammates, develop algorithms, write scripts to develop workflows, build predictive analytics, use automation, apply machine learning, and use the right combination of tools and frameworks to turn that set of disparate data points into objective answers to help senior leadership make informed decisions. You'll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in national security. Empower change with us. You Have: * Experience with using data science tools * Experience with data modeling, building workflows, and tasking * Experience with Python to perform data analysis, mining, and data visualization * Knowledge of JEMA * Ability to create mathematical and statistical models * TS/SCI clearance with a polygraph * BA or BS degree or 10 years of experience with analytics Nice If You Have: * Experience with machine learning * Knowledge of GEOINT TCPED * Knowledge of GEOINT tools * MA or MS degree Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance with polygraph is required. Build Your Career: At Booz Allen, we know the power of analytics and we're dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you'll have the chance to: * access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk  change the world with the Data Science Bowl-the world's premier data science for social good competition participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government You'll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We'll help you develop the career you want as you chart your own course for success. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>Apr</td>\n",
       "      <td>Jun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>Data Engineer, Senior with Security Clearance</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>VA</td>\n",
       "      <td>Herndon</td>\n",
       "      <td>91443</td>\n",
       "      <td>155868</td>\n",
       "      <td>Job Number: R0083334 Data Engineer, Senior Key Role: Develop data pipelines us ing Big Data services available in the Cloud. Architect data repositories, stand up data platforms, and write c us tom code for data ingestion, transformation, and aggregation. Create data models to support b us iness requirements. Work as a client-facing consultant providing solutions to Big Data us e cases. Develop continuo us integration ( CI ) and continuo us delivery ( CD ) pipelines to support automated deployment and automated testing. Basic Qualifications: -6+ years of experience with a modern programming language, including Python or Java -4+ years of experience with working in an agile development environment -4+ years of experience with developing extract, transform, load ( ETL ) and data pipelines -3+ years of experience with SQL -2+ years of experience with working in a Big Data environment -Ability to learn te chn ical concepts -Secret clearance -BA or BS degree Additional Qualifications: -Experience with Cloudera or Hortonworks -Experience with Hadoop ecosystem -Experience with data modeling concepts -Experience with leading a te chn ical team -Possession of excellent analytical and problem-solving skills -Possession of excellent oral and written communication skills, including communicating with multiple functional groups Clearance: Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required. We're an EOE that empowers our people-no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic-to fearlessly drive change.</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>May</td>\n",
       "      <td>Jun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2229 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Job_title  ... Valid_Month\n",
       "3     Senior Salesforce Developer                            ...  Jun       \n",
       "4     DEPUTY EXECUTIVE DIRECTOR, PROGRAM AND LEGAL ADVOCACY  ...  Jun       \n",
       "5     Emergency Veterinarian - NYC                           ...  Jun       \n",
       "6     ABA Therapist                                          ...  Jun       \n",
       "7     Construction Project Manager                           ...  Jun       \n",
       "...                            ...                           ...  ...       \n",
       "3319  Data Engineer/Architect with Security Clearance        ...  Jun       \n",
       "3320  Data Engineer with Security Clearance                  ...  Jun       \n",
       "3321  Data Engineer, Mid with Security Clearance             ...  Jun       \n",
       "3322  Data Modeler, Senior with Security Clearance           ...  Jun       \n",
       "3323  Data Engineer, Senior with Security Clearance          ...  Jun       \n",
       "\n",
       "[2229 rows x 14 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
